{
  "asin": "0387310738", 
  "price": 25.6, 
  "reviewText": "Usually considered to be a branch of artificial intelligence, especially at the present time, pattern recognition is defined in this book as the automatic discovery of regularities in data by the use of computer algorithms and the use of these regularities for classifying the data in different categories. The first part of this definition is typically referred to as `unsupervised learning' and the latter `supervised learning.' Both of these areas have resulted in a gargantuan amount of research due to their importance in areas such as medicine, genomics, network modeling, financial engineering, and voice recognition. This book emphasizes a \"conceptual\" approach to teaching pattern recognition, and therefore is highly valuable to those who need to learn the subject. Too often this field is taught purely from the formal standpoint, or conversely by the use of many trivial examples that illustrate the algorithms that are used. These approaches make the subject appear to be either a highly-developed mathematical one (which it is) or a cookbook that does not have a sound foundation. This book is one of the few that will allow the reader to gain a more in-depth understanding and appreciation of the subject as preparation for doing research and development in pattern recognition. The author claims that the book is self-contained as far as background in probability theory is concerned, but readers should still be prepared with this background in order to better appreciate the content. The Bayesian paradigm dominates the book, as it should given the current emphasis in research circles.Some of the highlights of the book include discussions on:* Relative entropy and mutual information. These two concepts have become very important in recent years, especially in the validation of pattern recognition models, the selection of relevant variables, and in independent component analysis.* Periodic variables and how they can be used in contexts where Gaussian distributions are problematic.* Markov chain Monte Carlo sampling, especially the role of the detailed balance condition in obtaining the acceptance probability for the Metropolis-Hastings algorithm.* Bayesian linear regression and its ability to deal with the over-fitting problem in calculations of maximum likelihood and the determination of model complexity.* Kernel learning (usually called support vector machines in other books).Some of the minuses of the book include:* Needs more in-depth discussion of Bayesian neural networks, over and above what is done in the book. The author's does devote a section in the book to this topic, but given its enormous importance, especially in automated learning and economic forecasting, more examples need to be included.* More real-world test cases need to be included, along with a comparison of the efficacies of different approaches, so as to illustrate the \"no free lunch\" philosophy.* More exercises that require more analysis on part of the reader, instead of derivation-type problems or straightforward numerical exercises.* Needs more details on independent component analysis. Only a few paragraphs are devoted to this important topic.", 
  "title": "Pattern Recognition and Machine Learning (Information Science and Statistics)"
}