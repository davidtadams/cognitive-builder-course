{
  "asin": "1107422221", 
  "price": 120.65, 
  "reviewText": "Over a decade ago, Peter Flach of Bristol University wrote a paper on the topic of &#34;On the state of the art in machine learning: A personal review&#34; in which he reviewed several, then recent books, related to developments in machine learning. This included Pat Langley&#8217;s Elements of Machine Learning (Morgan Kaufmann), Tom Mitchell&#8217;s Machine Learning (McGraw-Hill), and Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations by Ian Witten and Eibe Frank (Morgan Kaufman) among many others. Dr. Flach mentioned Michael Berry and Gordon Linoff&#8217;s Data Mining Techniques for Marketing, Sales, and Customer Support (John Wiley) for it's excellent writing style citing the paragraph below and commending &#34;I wish that all computer science textbooks were written like this.&#34;&#8220;People often find it hard to understand why the training set and test set are &#8220;tainted&#8221; once they have been used to build a model. An analogy may help: Imagine yourself back in the 5th grade. The class is taking a spelling test. Suppose that, at the end of the test period, the teacher asks you to estimate your own grade on the quiz by marking the words you got wrong. You will give yourself a very good grade, but your spelling will not improve. If, at the beginning of the period, you thought there should be an &#8216;e&#8217; at the end of &#8220;tomato&#8221;, nothing will have happened to change your mind when you grade your paper. No new data has entered the system. You need a test set! Now, imagine that at the end of the test the teacher allows you to look at the papersof several neighbors before grading your own. If they all agree that &#8220;tomato&#8221; has no final &#8216;e&#8217;, you may decide to mark your own answer wrong. If the teacher gives the same quiz tomorrow, you will do better. But how much better? If you use the papers of the very same neighbors to evaluate your performance tomorrow, you may still be fooling yourself. If they all agree that &#8220;potatoes&#8221; has no more need of an &#8216;e&#8217; then &#8220;tomato&#8221;, and you have changed your own guess to agree with theirs, then you will overestimate your actual grade on the second quiz as well. That is why the evaluation set should be different from the test set.&#8221; [3, pp. 76&#8211;77] Machine-Learning-9781107096394That is why when I recently came across  &#34;Machine Learning The Art and Science of Algorithms that Make Sense of Data&#34;, I decided to check it out and wasn't disappointed. Dr. Flach is the Professor of Artificial Intelligence at the University of Bristol and in this &#34;future classic&#34;, he left no stone unturned when it comes to clarity and explainability.  The book starts with a machine learning sampler, introduces the ingredients of machine learning fast progressing to Binary classification and Beyond. Written as a textbook, riddled with examples, foot-notes and figures, this text elaborates concept learning, tree models, rule models, linear models, distance-based models, probabilistic models to features and ensembles concluding with Machine learning experiments. I really enjoyed the &#34;Important points to remember&#34; section of the book as a quick refresher on machine-learning-commandments.The concept learning section seems to have been influenced by author's own research interest and is not discussed in as much details in contemporary machine learning texts. I also found frequent summarization of concepts to be quite helpful. Contrary to it's subtitle and compared to it's counterparts, the book however is light on algorithms and code, possibly on purpose. While it explains the concepts with examples, number of formal algorithms are kept to a minimum. This may aid in clarity and help avoiding recipe-book-syndrome while making it potentially inaccessible to practitioners. Great at basics, the text also falls short on elaboration of intermediate to advance topics such as LDA, kernel methods, PCA, RKHS, and convex optimization. For instance, in chapter 10 &#34;Matrix transformations and decompositions&#34; could have been made an appendix while expanding upon meaningful topics like LSA and use cases of sparse matrix (pg 327). It is definitely not the book's fault; but rather of this reader expecting too much from an introductory text just because author explains everything so well!As a text book on Machine learning as the Art and Science of Algorithms, Peter Flach definitely delivers on the promise of clarity, with well chosen illustrations and example based approach. A highly recommended reading for all who would like to understand the principles behind machine learning techniques.Materials can be downloaded from here which generously include excerpts with background material and literature references, full set of 540 lecture slides in PDF including all figures in the book with LaTeX beamer source of the above.", 
  "title": "Machine Learning: The Art and Science of Algorithms that Make Sense of Data"
}