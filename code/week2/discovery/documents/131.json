{
  "asin": "0387848576", 
  "price": 45.45, 
  "reviewText": "This is a quite interesting, and extremely useful book, but it is wearing to read in large chunks.  The problem, if you want to call it that, is that it is essentially a 700 page catalogue of clever hacks in statistical learning.  From a technical point of view it is well-ehough structured, but there is not the slightest trace of an overarching philosophy.  And if you don't actually have a philosophical perspective in place before you start, the read you face might well be an even harder grind.  Be warned.Some of the reviews here complain that there is too much math.  I don't think that is an issue.  If you have decent intuitions in geometry, linear algebra, probability and information theory, then you should be able to cruise through and/or browse in a fairly relaxed way. If you don't have those intuitions, then you are attempting to read the wrong book.There were a couple of things that I expected (things I happen to know a bit about), but that were missing.  On the unsupervised learning side, the discussion of Gaussian mixture clustering was, I thought, a bit short and superficial, and did not bring out the combination of theoretical and practical power that the method offers.  On the supervised learning side, I was surprised that a book that dedicates so much time to linear regression finds no room for a discussion of Gaussian process regression as far as I could see (the nearest point of approach is the use of Gaussian radial basis functions [oops: having written that, I immediately came across a brief discussion (S5.8.1) of, essentially, GP regression - though with no reference to standard literature]).", 
  "title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)"
}